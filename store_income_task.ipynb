{"cells":[{"cell_type":"markdown","metadata":{"id":"lqt_yzRy16Wj"},"source":["## Compulsory Task \n","\n","In this compulsory task you will clean the country column and parse the date column in the **store_income_data_task.csv** file."]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[],"source":["# Import libraries\n","import pandas as pd\n","import fuzzywuzzy as fuzzywuzzy\n","from fuzzywuzzy import process\n","import datetime\n","from datetime import date"]},{"cell_type":"code","execution_count":66,"metadata":{"id":"vBP3WN2O16Wp"},"outputs":[],"source":["# Load up store_income_data.csv\n","df = pd.read_csv(\"store_income_data_task.csv\")"]},{"cell_type":"markdown","metadata":{"id":"ItqLwumA16Wr"},"source":["1. Take a look at all the unique values in the \"country\" column. Then, convert the column to lowercase and remove any trailing white spaces."]},{"cell_type":"code","execution_count":67,"metadata":{"id":"sLkzt4Hr16Wr"},"outputs":[{"data":{"text/plain":["array(['United States/', 'Britain', ' United States', 'Britain/',\n","       ' United Kingdom', 'U.K.', 'SA ', 'U.K/', 'America',\n","       'United Kingdom', nan, 'united states', ' S.A.', 'England ', 'UK',\n","       'S.A./', 'ENGLAND', 'BRITAIN', 'U.K', 'U.K ', 'America/', 'SA.',\n","       'S.A. ', 'u.k', 'uk', ' ', 'UK.', 'England/', 'england',\n","       ' Britain', 'united states of america', 'UK/', 'SA/', 'SA',\n","       'England.', 'UNITED KINGDOM', 'America.', 'S.A..', 's.a.', ' U.K',\n","       ' United States of America', 'Britain ', 'England', ' SA',\n","       'United States of America.', 'United States of America/',\n","       'United States.', 's. africasouth africa', ' England',\n","       'United Kingdom ', 'United States of America ', ' UK',\n","       'united kingdom', 'AMERICA', 'America ',\n","       'UNITED STATES OF AMERICA', ' S. AfricaSouth Africa', 'america',\n","       'S. AFRICASOUTH AFRICA', 'Britain.', '/', 'United Kingdom.',\n","       'United States', ' America', 'UNITED STATES', 'sa',\n","       'United States of America', 'UK ', 'United States ',\n","       'S. AfricaSouth Africa/', 'S.A.', 'United Kingdom/',\n","       'S. AfricaSouth Africa ', 'S. AfricaSouth Africa.',\n","       'S. AfricaSouth Africa', '.', 'britain'], dtype=object)"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["# Looking at the unique values in the \"country\" column\n","df.country.unique()"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[],"source":["# Converting the values in the column to lowercase\n","df.country = df.country.str.lower()\n","# Removing any trailing white spaces\n","df.country = df.country.str.strip()"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[{"data":{"text/plain":["array(['united states/', 'britain', 'united states', 'britain/',\n","       'united kingdom', 'u.k.', 'sa', 'u.k/', 'america', nan, 's.a.',\n","       'england', 'uk', 's.a./', 'u.k', 'america/', 'sa.', '', 'uk.',\n","       'england/', 'united states of america', 'uk/', 'sa/', 'england.',\n","       'america.', 's.a..', 'united states of america.',\n","       'united states of america/', 'united states.',\n","       's. africasouth africa', 'britain.', '/', 'united kingdom.',\n","       's. africasouth africa/', 'united kingdom/',\n","       's. africasouth africa.', '.'], dtype=object)"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["# The country column after string manipulation\n","df.country.unique()"]},{"cell_type":"markdown","metadata":{"id":"P6dcDc4P16Ws"},"source":["2. Note that there should only be three separate countries. Eliminate all variations, so that 'South Africa', 'United Kingdom' and 'United States' are the only three countries."]},{"cell_type":"code","execution_count":70,"metadata":{"id":"qeV3CxMR16Ws"},"outputs":[],"source":["def replace_country_variations(df, column, string_match, matching_threshold=90):\n","    \"\"\"\n","    The function that finds the matching\n","    between the variations found in the dataframe's column\n","    and the specific input string and decides to replace\n","    the variation with the string if the match exceeds the input threshold.\n","\n","    Parameters\n","    ----------\n","    df : dataframe\n","        the dataframe containing the column with variations\n","    column : string\n","        the name of the column with variations\n","    string_match : string\n","        the specific string chosen to match with variations\n","    matching_threshold: int\n","        the threshold suggesting if the match found is close\n","\n","    \"\"\"\n","    unique_strings = df[column].unique()\n","\n","    matches = fuzzywuzzy.process.extract(\n","        string_match, unique_strings, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio\n","    )\n","\n","    close_matches = [match[0] for match in matches if match[1] >= matching_threshold]\n","\n","    rows_with_close_matches = df[column].isin(close_matches)\n","\n","    df.loc[rows_with_close_matches, column] = string_match\n","\n","    print(\"The replacement process with \", string_match, \" is completed!\")"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The replacement process with  united kingdom  is completed!\n","The replacement process with  united states  is completed!\n","The replacement process with  united states of america  is completed!\n","The replacement process with  s. africasouth africa  is completed!\n","The replacement process with  britain  is completed!\n","The replacement process with  england  is completed!\n","The replacement process with  america  is completed!\n","The replacement process with  uk  is completed!\n","The replacement process with  sa  is completed!\n"]}],"source":["# Removing all nan values and switching them with 'Other'\n","df.country.fillna(value=\"Other\", inplace=True)\n","\n","# Replacing the variations\n","replace_country_variations(df, \"country\", \"united kingdom\")\n","replace_country_variations(df, \"country\", \"united states\")\n","replace_country_variations(df, \"country\", \"united states of america\")\n","replace_country_variations(df, \"country\", \"s. africasouth africa\")\n","replace_country_variations(df, \"country\", \"britain\")\n","replace_country_variations(df, \"country\", \"england\")\n","replace_country_variations(df, \"country\", \"america\")\n","replace_country_variations(df, \"country\", \"uk\")\n","replace_country_variations(df, \"country\", \"sa\")"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[{"data":{"text/plain":["array(['united states', 'britain', 'united kingdom', 'u.k.', 'sa', 'u.k/',\n","       'america', 'Other', 's.a.', 'england', 'uk', 's.a./', 'u.k', '',\n","       'united states of america', 's.a..', 's. africasouth africa', '/',\n","       '.'], dtype=object)"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["# Checking for the variations undetected by the replacement function\n","df.country.unique()"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"data":{"text/plain":["array(['united states', 'britain', 'united kingdom', 'uk', 'sa',\n","       'america', 'Other', 'england', 'united states of america',\n","       's africasouth africa'], dtype=object)"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}],"source":["# First replacing signs like: '/', '.' with ''\n","# Since there are values that contain them\n","# And some values are equal to them\n","df.country.replace(regex=[\"\\/\", \"\\.\"], value=\"\", inplace=True)\n","# Then finding the empty string and replacing them with 'Other'\n","# As they can be missing values like nan\n","df.country.replace(regex=[\"\"], value=\"Other\", inplace=True)\n","# Checking the unique values\n","df.country.unique()"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[],"source":["def switching_titles_to_abbrevation(country_name):\n","    \"\"\"\n","    The function which takes the name of the country\n","    and returns the abbrevatio of the name\n","\n","    Parameters\n","    ----------\n","    country_name : string\n","        the string containing the name of the country\n","\n","    Returns\n","    ----------\n","        abbreviation: string\n","            the abbreviation of the country's name\n","    \"\"\"\n","    # Splitting the name by the whitespaces\n","    splitted_name = country_name.split(\" \")\n","    # Taking the first letter of the first part\n","    first_letter_of_first_part = splitted_name[0][0]\n","    # Taking the first letter of the second part\n","    first_letter_of_second_part = splitted_name[1][0]\n","    # Concating the two letters\n","    abbreviation = first_letter_of_first_part + first_letter_of_second_part\n","    return abbreviation"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[{"data":{"text/plain":["array(['us', 'britain', 'uk', 'sa', 'america', 'Other', 'england'],\n","      dtype=object)"]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["# Shortening the title of the countries\n","# Only for the titles made of more than two words\n","# https://www.geeksforgeeks.org/applying-lambda-functions-to-pandas-dataframe/\n","df.country = df.country.apply(\n","    lambda x: switching_titles_to_abbrevation(x) if len(x.split(\" \")) >= 2 else x\n",")\n","\n","df.country.unique()"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[{"data":{"text/plain":["array(['United States', 'United Kingdom', 'South Africa', 'Other'],\n","      dtype=object)"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["# Manually matching the remaining varieties with the specific value\n","uk_match = \"United Kingdom\"\n","us_match = \"United States\"\n","sa_match = \"South Africa\"\n","\n","df.country.replace(\"britain\", uk_match, inplace=True)\n","df.country.replace(\"uk\", uk_match, inplace=True)\n","df.country.replace(\"us\", us_match, inplace=True)\n","df.country.replace(\"sa\", sa_match, inplace=True)\n","df.country.replace(\"america\", us_match, inplace=True)\n","df.country.replace(\"england\", uk_match, inplace=True)\n","\n","# Checking the unique values\n","df.country.unique()"]},{"cell_type":"markdown","metadata":{"id":"UJZDMTwP16Ws"},"source":["3. Create a new column called `days_ago` in the DataFrame that is a copy of the 'date_measured' column but instead it is a number that shows how many days ago it was measured from the current date. Note that the current date can be obtained using `datetime.date.today()`."]},{"cell_type":"code","execution_count":55,"metadata":{"id":"gMJbN84P16Wt"},"outputs":[{"data":{"text/plain":["dtype('O')"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["# Creating a copy of the 'date_measured' column\n","df[\"days_ago\"] = df.date_measured.copy()\n","\n","# Checking the type of the column\n","df.days_ago.dtype"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"data":{"text/plain":["0      19846\n","1      19846\n","2      19846\n","3      19846\n","4      19846\n","       ...  \n","995    19846\n","996    19846\n","997    19846\n","998    19846\n","999    19846\n","Name: days_ago, Length: 1000, dtype: int64"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["# Converting the 'days_ago' column to datetime type\n","df[\"days_ago\"] = pd.to_datetime(\n","    df[\"days_ago\"], format=\"%d %B %Y\", infer_datetime_format=True\n",")\n","\n","# Converting the today date to the compatible format\n","today_date = pd.to_datetime(\n","    datetime.date.today(), format=\"%d %B %Y\", infer_datetime_format=True\n",")\n","\n","# Calculating the number of days passed\n","# Connverting it to int since the number of days is requested\n","df.days_ago = (today_date - df[\"days_ago\"]).dt.days\n","\n","df.days_ago"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"vscode":{"interpreter":{"hash":"63d17dc58a06b6a6d4136fb13c245dafcf53668da37b1c3052c24d689135f5bb"}}},"nbformat":4,"nbformat_minor":0}
