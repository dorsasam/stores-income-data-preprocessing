{"cells":[{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["# Import libraries\n","import pandas as pd\n","import fuzzywuzzy as fuzzywuzzy\n","from fuzzywuzzy import process\n","import datetime\n","from datetime import date"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"vBP3WN2O16Wp"},"outputs":[],"source":["# Load up store_income_data.csv\n","df = pd.read_csv(\"store_income_data_task.csv\")"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"data":{"text/plain":["['id',\n"," 'store_name',\n"," 'store_email',\n"," 'department',\n"," 'income',\n"," 'date_measured',\n"," 'country',\n"," 'days_ago']"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["df.columns.tolist()"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"sLkzt4Hr16Wr"},"outputs":[{"data":{"text/plain":["array(['United States/', 'Britain', ' United States', 'Britain/',\n","       ' United Kingdom', 'U.K.', 'SA ', 'U.K/', 'America',\n","       'United Kingdom', nan, 'united states', ' S.A.', 'England ', 'UK',\n","       'S.A./', 'ENGLAND', 'BRITAIN', 'U.K', 'U.K ', 'America/', 'SA.',\n","       'S.A. ', 'u.k', 'uk', ' ', 'UK.', 'England/', 'england',\n","       ' Britain', 'united states of america', 'UK/', 'SA/', 'SA',\n","       'England.', 'UNITED KINGDOM', 'America.', 'S.A..', 's.a.', ' U.K',\n","       ' United States of America', 'Britain ', 'England', ' SA',\n","       'United States of America.', 'United States of America/',\n","       'United States.', 's. africasouth africa', ' England',\n","       'United Kingdom ', 'United States of America ', ' UK',\n","       'united kingdom', 'AMERICA', 'America ',\n","       'UNITED STATES OF AMERICA', ' S. AfricaSouth Africa', 'america',\n","       'S. AFRICASOUTH AFRICA', 'Britain.', '/', 'United Kingdom.',\n","       'United States', ' America', 'UNITED STATES', 'sa',\n","       'United States of America', 'UK ', 'United States ',\n","       'S. AfricaSouth Africa/', 'S.A.', 'United Kingdom/',\n","       'S. AfricaSouth Africa ', 'S. AfricaSouth Africa.',\n","       'S. AfricaSouth Africa', '.', 'britain'], dtype=object)"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["# Looking at the unique values in the \"country\" column\n","df.country.unique()"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["# Converting the values in the column to lowercase\n","df.country = df.country.str.lower()\n","# Removing any trailing white spaces\n","df.country = df.country.str.strip()"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"data":{"text/plain":["array(['united states/', 'britain', 'united states', 'britain/',\n","       'united kingdom', 'u.k.', 'sa', 'u.k/', 'america', nan, 's.a.',\n","       'england', 'uk', 's.a./', 'u.k', 'america/', 'sa.', '', 'uk.',\n","       'england/', 'united states of america', 'uk/', 'sa/', 'england.',\n","       'america.', 's.a..', 'united states of america.',\n","       'united states of america/', 'united states.',\n","       's. africasouth africa', 'britain.', '/', 'united kingdom.',\n","       's. africasouth africa/', 'united kingdom/',\n","       's. africasouth africa.', '.'], dtype=object)"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["# The country column after string manipulation\n","df.country.unique()"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"qeV3CxMR16Ws"},"outputs":[],"source":["def replace_country_variations(df, column, string_match, matching_threshold=90):\n","    \"\"\"\n","    The function that finds the matching\n","    between the variations found in the dataframe's column\n","    and the specific input string and decides to replace\n","    the variation with the string if the match exceeds the input threshold.\n","\n","    Parameters\n","    ----------\n","    df : dataframe\n","        the dataframe containing the column with variations\n","    column : string\n","        the name of the column with variations\n","    string_match : string\n","        the specific string chosen to match with variations\n","    matching_threshold: int\n","        the threshold suggesting if the match found is close\n","\n","    \"\"\"\n","    unique_strings = df[column].unique()\n","\n","    matches = fuzzywuzzy.process.extract(\n","        string_match, unique_strings, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio\n","    )\n","    print(matches)\n","\n","    close_matches = [match[0] for match in matches if match[1] >= matching_threshold]\n","\n","    rows_with_close_matches = df[column].isin(close_matches)\n","\n","    df.loc[rows_with_close_matches, column] = string_match\n","\n","    print(\"The replacement process with \", string_match, \" is completed!\")"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[('united kingdom', 100), ('united kingdom.', 100), ('united kingdom/', 100), ('united states/', 52), ('united states', 52), ('united states.', 52), ('united states of america', 47), ('united states of america.', 47), ('united states of america/', 47), ('u.k.', 35)]\n","The replacement process with  united kingdom  is completed!\n","[('united states/', 100), ('united states', 100), ('united states.', 100), ('united states of america', 70), ('united states of america.', 70), ('united states of america/', 70), ('united kingdom', 52), ('britain', 30), ('britain/', 30), ('america', 30)]\n","The replacement process with  united states  is completed!\n","[('united states of america', 100), ('united states of america.', 100), ('united states of america/', 100), ('united states', 70), ('america', 45), ('america/', 45), ('america.', 45), ('united kingdom', 42), ('s. africasouth africa', 41), ('s. africasouth africa/', 41)]\n","The replacement process with  united states of america  is completed!\n","[('s. africasouth africa', 100), ('s. africasouth africa/', 100), ('s. africasouth africa.', 100), ('united states of america', 41), ('america', 37), ('america/', 37), ('america.', 37), ('britain', 30), ('britain/', 30), ('britain.', 30)]\n","The replacement process with  s africasouth africa  is completed!\n","[('britain', 100), ('britain/', 100), ('britain.', 100), ('america', 43), ('america/', 43), ('america.', 43), ('united states of america', 32), ('england', 29), ('england/', 29), ('england.', 29)]\n","The replacement process with  britain  is completed!\n","[('england', 100), ('england/', 100), ('england.', 100), ('united kingdom', 38), ('united states', 30), ('america', 29), ('america/', 29), ('america.', 29), ('sa', 22), ('sa.', 22)]\n","The replacement process with  england  is completed!\n","[('america', 100), ('america/', 100), ('america.', 100), ('united states of america', 45), ('britain', 43), ('s africasouth africa', 37), ('Other', 33), ('united states', 30), ('sa', 22), ('sa.', 22)]\n","The replacement process with  america  is completed!\n","[('uk', 100), ('uk.', 100), ('uk/', 100), ('u.k.', 40), ('u.k/', 40), ('u.k', 40), ('united states', 13), ('united kingdom', 12), ('s africasouth africa', 9), ('united states of america', 8)]\n","The replacement process with  uk  is completed!\n","[('sa', 100), ('sa.', 100), ('sa/', 100), ('s.a.', 40), ('s.a./', 40), ('s.a..', 40), ('united states', 27), ('britain', 22), ('america', 22), ('england', 22)]\n","The replacement process with  sa  is completed!\n"]}],"source":["# Removing all nan values and switching them with 'Other'\n","df.country.fillna(value=\"Other\", inplace=True)\n","\n","# Replacing the variations\n","replace_country_variations(df, \"country\", \"united kingdom\")\n","replace_country_variations(df, \"country\", \"united states\")\n","replace_country_variations(df, \"country\", \"united states of america\")\n","replace_country_variations(df, \"country\", \"s africasouth africa\")\n","replace_country_variations(df, \"country\", \"britain\")\n","replace_country_variations(df, \"country\", \"england\")\n","replace_country_variations(df, \"country\", \"america\")\n","replace_country_variations(df, \"country\", \"uk\")\n","replace_country_variations(df, \"country\", \"sa\")"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"data":{"text/plain":["array(['united states', 'britain', 'united kingdom', 'u.k.', 'sa', 'u.k/',\n","       'america', 'Other', 's.a.', 'england', 'uk', 's.a./', 'u.k', '',\n","       'united states of america', 's.a..', 's africasouth africa', '/',\n","       '.'], dtype=object)"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["# Checking for the variations undetected by the replacement function\n","df.country.unique()"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"data":{"text/plain":["array(['united states', 'britain', 'united kingdom', 'uk', 'sa',\n","       'america', 'Other', 'england', 'united states of america',\n","       's africasouth africa'], dtype=object)"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["# First replacing signs like: '/', '.' with ''\n","# Since there are values that contain them\n","# And some values are equal to them\n","df.country.replace(regex=[\"\\/\", \"\\.\"], value=\"\", inplace=True)\n","# Then finding the empty string and replacing them with 'Other'\n","# As they can be missing values like nan\n","df.country.replace(regex=[\"\"], value=\"Other\", inplace=True)\n","# Checking the unique values\n","df.country.unique()"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["def switching_titles_to_abbrevation(country_name):\n","    \"\"\"\n","    The function which takes the name of the country\n","    and returns the abbrevatio of the name\n","\n","    Parameters\n","    ----------\n","    country_name : string\n","        the string containing the name of the country\n","\n","    Returns\n","    ----------\n","        abbreviation: string\n","            the abbreviation of the country's name\n","    \"\"\"\n","    # Splitting the name by the whitespaces\n","    splitted_name = country_name.split(\" \")\n","    # Taking the first letter of the first part\n","    first_letter_of_first_part = splitted_name[0][0]\n","    # Taking the first letter of the second part\n","    first_letter_of_second_part = splitted_name[1][0]\n","    # Concating the two letters\n","    abbreviation = first_letter_of_first_part + first_letter_of_second_part\n","    return abbreviation"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"data":{"text/plain":["array(['us', 'britain', 'uk', 'sa', 'america', 'Other', 'england'],\n","      dtype=object)"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["# Shortening the title of the countries\n","# Only for the titles made of more than two words\n","# https://www.geeksforgeeks.org/applying-lambda-functions-to-pandas-dataframe/\n","df.country = df.country.apply(\n","    lambda x: switching_titles_to_abbrevation(x) if len(x.split(\" \")) >= 2 else x\n",")\n","\n","df.country.unique()"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"data":{"text/plain":["array(['United States', 'United Kingdom', 'South Africa', 'Other'],\n","      dtype=object)"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["# Manually matching the remaining varieties with the specific value\n","uk_match = \"United Kingdom\"\n","us_match = \"United States\"\n","sa_match = \"South Africa\"\n","\n","df.country.replace(\"britain\", uk_match, inplace=True)\n","df.country.replace(\"uk\", uk_match, inplace=True)\n","df.country.replace(\"us\", us_match, inplace=True)\n","df.country.replace(\"sa\", sa_match, inplace=True)\n","df.country.replace(\"america\", us_match, inplace=True)\n","df.country.replace(\"england\", uk_match, inplace=True)\n","\n","# Checking the unique values\n","df.country.unique()"]},{"cell_type":"code","execution_count":57,"metadata":{"id":"gMJbN84P16Wt"},"outputs":[{"data":{"text/plain":["dtype('O')"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["# Creating a copy of the 'date_measured' column\n","df[\"days_ago\"] = df.date_measured.copy()\n","\n","# Checking the type of the column\n","df.days_ago.dtype"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"data":{"text/plain":["0      19846\n","1      19846\n","2      19846\n","3      19846\n","4      19846\n","       ...  \n","995    19846\n","996    19846\n","997    19846\n","998    19846\n","999    19846\n","Name: days_ago, Length: 1000, dtype: int64"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["# Converting the 'days_ago' column to datetime type\n","df[\"days_ago\"] = pd.to_datetime(\n","    df[\"days_ago\"], format=\"%d %B %Y\", infer_datetime_format=True\n",")\n","\n","# Converting the today date to the compatible format\n","today_date = pd.to_datetime(\n","    datetime.date.today(), format=\"%d %B %Y\", infer_datetime_format=True\n",")\n","\n","# Calculating the number of days passed\n","# Connverting it to int since the number of days is requested\n","df.days_ago = (today_date - df[\"days_ago\"]).dt.days\n","\n","df.days_ago"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"vscode":{"interpreter":{"hash":"63d17dc58a06b6a6d4136fb13c245dafcf53668da37b1c3052c24d689135f5bb"}}},"nbformat":4,"nbformat_minor":0}
